<!DOCTYPE html>
<html>
<head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script type="text/javascript" src="/js/theme.js"></script>
    <meta name="description" content="1.框架处理监督式机器学习什么是（监督式）机器学习？简单来说，它的定义如下：  机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。  标签标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目">
<meta name="keywords" content="Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning by Google">
<meta property="og:url" content="http://hijia.xin/2018/10/24/Machine-Learning-by-Google/index.html">
<meta property="og:site_name" content="Begin">
<meta property="og:description" content="1.框架处理监督式机器学习什么是（监督式）机器学习？简单来说，它的定义如下：  机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。  标签标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://hijia.xin/picture/google/CricketPoints.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/CricketLine.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/LossSideBySide.png">
<meta property="og:image" content="http://hijia.xin/picture/google/GradientDescentDiagram.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/convex.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/GradientDescentStartingPoint.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/GradientDescentNegativeGradient.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/GradientDescentGradientStep.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/LearningRateTooSmall.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/LearningRateTooLarge.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/LearningRateJustRight.svg">
<meta property="og:image" content="http://hijia.xin/picture/google/TFHierarchy.svg">
<meta property="og:updated_time" content="2018-11-05T08:53:53.044Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Machine Learning by Google">
<meta name="twitter:description" content="1.框架处理监督式机器学习什么是（监督式）机器学习？简单来说，它的定义如下：  机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。  标签标签是我们要预测的事物，即简单线性回归中的 y 变量。标签可以是小麦未来的价格、图片中显示的动物品种、音频剪辑的含义或任何事物。 特征特征是输入变量，即简单线性回归中的 x 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目">
<meta name="twitter:image" content="http://hijia.xin/picture/google/CricketPoints.svg">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Machine Learning by Google</title>
    <!-- styles -->
    <link rel="stylesheet" href="/css/style.css">
    <!-- persian styles -->
    
      <link rel="stylesheet" href="/css/rtl.css">
    
    <!-- rss --><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    
    
</head>

<body class="max-width mx-auto px3 ltr">    
      <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/categories">Categories</a></li>
         
          <li><a href="/search/">Search</a></li>
         
          <li><a href="/about/">About</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2018/11/08/Something-About-Android/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2018/10/17/Introduction-to-Marketing/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
    </span>
    <br/>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-框架处理"><span class="toc-number">1.</span> <span class="toc-text">1.框架处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#监督式机器学习"><span class="toc-number">1.1.</span> <span class="toc-text">监督式机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#标签"><span class="toc-number">1.2.</span> <span class="toc-text">标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征"><span class="toc-number">1.3.</span> <span class="toc-text">特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#样本"><span class="toc-number">1.4.</span> <span class="toc-text">样本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型"><span class="toc-number">1.5.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归与分类"><span class="toc-number">1.6.</span> <span class="toc-text">回归与分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-深入了解机器学习"><span class="toc-number">2.</span> <span class="toc-text">2.深入了解机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性回归"><span class="toc-number">2.1.</span> <span class="toc-text">线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练与损失"><span class="toc-number">2.2.</span> <span class="toc-text">训练与损失</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-降低误差"><span class="toc-number">3.</span> <span class="toc-text">3.降低误差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#迭代方法"><span class="toc-number">3.1.</span> <span class="toc-text">迭代方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降法"><span class="toc-number">3.2.</span> <span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习速率"><span class="toc-number">3.3.</span> <span class="toc-text">学习速率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#随机梯度下降法"><span class="toc-number">3.4.</span> <span class="toc-text">随机梯度下降法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用-TensorFlow-的起始步骤"><span class="toc-number">4.</span> <span class="toc-text">使用 TensorFlow 的起始步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#工具包"><span class="toc-number">4.1.</span> <span class="toc-text">工具包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-estimator-API"><span class="toc-number">4.2.</span> <span class="toc-text">tf.estimator API</span></a></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div id="ct" style="z-index: 9999; position: fixed ! important; right: 20px; bottom: 20px;" onclick="javascript:sclick();">
      <img src="/images/logo.png" title="change theme" alt="changetheme" width="30" height="30">
    </div>
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
<a href="/">
    
    <h1 class="posttitle" itemprop="name headline">
        Machine Learning by Google
    </h1>



</a>
    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Begin</span>
      </span>
      
    <div class="postdate">
        <time datetime="2018-10-24T13:30:11.000Z" itemprop="datePublished">2018-10-24</time>
    </div>


      
    <div class="article-category">
        <i class="fas fa-archive"></i>
        <a class="category-link" href="/categories/Machine-Learning/">Machine Learning</a>
    </div>


      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <h2 id="1-框架处理"><a href="#1-框架处理" class="headerlink" title="1.框架处理"></a>1.框架处理</h2><h3 id="监督式机器学习"><a href="#监督式机器学习" class="headerlink" title="监督式机器学习"></a>监督式机器学习</h3><p>什么是（监督式）机器学习？简单来说，它的定义如下：</p>
<ul>
<li>机器学习系统通过学习如何组合输入信息来对从未见过的数据做出有用的预测。</li>
</ul>
<h3 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h3><p><strong>标签</strong>是我们要预测的事物，即简单线性回归中的 <code>y</code> 变量。标签可以是<strong>小麦未来的价格</strong>、图片中显示的<strong>动物品种</strong>、音频剪辑的含义或任何事物。</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><p><strong>特征</strong>是<strong>输入变量</strong>，即简单线性回归中的 <code>x</code> 变量。简单的机器学习项目可能会使用单个特征，而比较复杂的机器学习项目可能会使用数百万个特征，按如下方式指定：
$$
{x_1,x_2,…x_N}
$$
在垃圾邮件检测器示例中，特征可能包括：</p>
<ul>
<li>电子邮件文本中的字词</li>
<li>发件人的地址</li>
<li>发送电子邮件的时段</li>
<li>电子邮件中包含“一种奇怪的把戏”这样的短语。</li>
</ul>
<h3 id="样本"><a href="#样本" class="headerlink" title="样本"></a>样本</h3><p><strong>样本</strong>是指数据的特定实例：<strong>x</strong>。（我们采用粗体 <strong>x</strong> 表示它是一个矢量。）我们将样本分为以下两类：</p>
<ul>
<li>有标签样本</li>
<li>无标签样本</li>
</ul>
<p><strong>有标签样本</strong>同时包含特征和标签。即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">代标签例子: &#123;features, label&#125;: (x, y)</span><br></pre></td></tr></table></figure>
<p>我们使用有标签样本来<strong>训练</strong>模型。在我们的垃圾邮件检测器示例中，有标签样本是用户明确标记为“垃圾邮件”或“非垃圾邮件”的各个电子邮件。</p>
<p>例如，下表显示了从包含加利福尼亚州房价信息的<a href="https://developers.google.com/machine-learning/crash-course/california-housing-data-description" target="_blank" rel="noopener">数据集</a>中抽取的 5 个有标签样本：</p>
<p><div style="width:device-width;overflow:auto">
  <table border="1" class="dataframe">
    <thead>
      <tr style="text-align: right;">
        <th>housingMedianAge</th>
        <th>totalRooms</th>
        <th>totalBedrooms</th>
        <th>medianHouseValue(标签) </th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>15</td>
        <td>5612</td>
        <td>1283</td>
        <td>66900</td>
      </tr>
      <tr>
        <td>19</td>
        <td>7650</td>
        <td>1901</td>
        <td>80100</td>
      </tr>
      <tr>
        <td>17</td>
        <td>720</td>
        <td>174</td>
        <td>85700</td>
      </tr>
      <tr>
        <td>14</td>
        <td>1501</td>
        <td>337</td>
        <td>73400</td>
      </tr>
      <tr>
        <td>20</td>
        <td>1454</td>
        <td>326</td>
        <td>65500</td>
      </tr></tbody></table></div></p>
<p>无标签样本**包含特征，但不包含标签。即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">无标签例子: &#123;features, ?&#125;: (x, ?)</span><br></pre></td></tr></table></figure>
<p>在使用有标签样本训练了我们的模型之后，我们会使用该模型来预测无标签样本的标签。在垃圾邮件检测器示例中，无标签样本是用户尚未添加标签的新电子邮件。</p>
<h3 id="模型"><a href="#模型" class="headerlink" title="模型"></a>模型</h3><p>模型定义了特征与标签之间的关系。例如，垃圾邮件检测模型可能会将某些特征与“垃圾邮件”紧密联系起来。我们来重点介绍一下模型生命周期的两个阶段：</p>
<ul>
<li><strong>训练</strong>表示创建或<strong>学习</strong>模型。也就是说，您向模型展示有标签样本，让模型逐渐学习特征与标签之间的关系。</li>
<li><strong>推断</strong>表示将训练后的模型应用于无标签样本。也就是说，您使用训练后的模型来做出有用的预测 (<code>y&#39;</code>)。例如，在推断期间，您可以针对新的无标签样本预测 <code>medianHouseValue</code>。</li>
</ul>
<h3 id="回归与分类"><a href="#回归与分类" class="headerlink" title="回归与分类"></a>回归与分类</h3><p><strong>回归</strong>模型<strong>可预测连续值</strong>。例如，回归模型做出的预测可回答如下问题：</p>
<ul>
<li>加利福尼亚州一栋房产的价值是多少？</li>
<li>用户点击此广告的概率是多少？</li>
</ul>
<p><strong>分类</strong>模型<strong>可预测离散值</strong>。例如，分类模型做出的预测可回答如下问题：</p>
<ul>
<li>某个指定电子邮件是垃圾邮件还是非垃圾邮件？</li>
<li>这是一张狗、猫还是仓鼠图片？</li>
</ul>
<h2 id="2-深入了解机器学习"><a href="#2-深入了解机器学习" class="headerlink" title="2.深入了解机器学习"></a>2.深入了解机器学习</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>人们早就知晓，相比凉爽的天气，蟋蟀在较为炎热的天气里鸣叫更为频繁。数十年来，专业和业余昆虫学者已将每分钟的鸣叫声和温度方面的数据编入目录。Ruth 阿姨将她喜爱的蟋蟀数据库作为生日礼物送给您，并邀请您自己利用该数据库训练一个模型，从而预测鸣叫声与温度的关系。</p>
<p>首先建议您将数据绘制成图表，了解下数据的分布情况：</p>
<p><img src="/picture/google/CricketPoints.svg" alt="每分钟啁啾(x轴)与温度(y轴)的原始数据。"></p>
<p><strong>图 1. 每分钟的鸣叫声与温度（摄氏度）的关系。</strong></p>
<p>毫无疑问，此曲线图表明温度随着鸣叫声次数的增加而上升。鸣叫声与温度之间的关系是线性关系吗？是的，您可以绘制一条直线来近似地表示这种关系，如下所示：</p>
<p><img src="/picture/google/CricketLine.svg" alt="建立每分钟啁啾（x轴）与温度（y轴）关系的最佳线。"></p>
<p><strong>图 2. 线性关系。</strong></p>
<p>事实上，虽然该直线并未精确无误地经过每个点，但针对我们拥有的数据，清楚地显示了鸣叫声与温度之间的关系。只需运用一点代数知识，您就可以将这种关系写下来，如下所示：
$$
y=mx+b
$$
其中：</p>
<ul>
<li>$y$ 指的是温度（以摄氏度表示），即我们试图预测的值。</li>
<li>$m$ 指的是直线的斜率。</li>
<li>$x$ 指的是每分钟的鸣叫声次数，即输入特征的值。</li>
<li>$b$ 指的是 y 轴截距。</li>
</ul>
<p>按照机器学习的惯例，您需要写一个存在细微差别的模型方程式：
$$
y′=b+w_1x_1
$$
其中：</p>
<ul>
<li>$y′$ 指的是预测标签（理想输出值）。</li>
<li>$b$ 指的是偏差（y 轴截距）。而在一些机器学习文档中，它称为 $w_0$。</li>
<li>$w_1$ 指的是特征 1 的权重。权重与上文中用 $m$ 表示的“斜率”的概念相同。</li>
<li>$x_1$ 指的是特征（已知输入项）。</li>
</ul>
<p>要根据新的每分钟的鸣叫声值 $x_1$ <strong>推断</strong>（预测）温度 $y′$，只需将 $x_1$ 值代入此模型即可。</p>
<p>下标（例如 $w_1$ 和 $x_1$）预示着可以用多个特征来表示更复杂的模型。例如，具有三个特征的模型可以采用以下方程式：
$$
y′=b+w_1x_1+w_2x_2+w_3x_3
$$</p>
<h3 id="训练与损失"><a href="#训练与损失" class="headerlink" title="训练与损失"></a>训练与损失</h3><p>简单来说，<strong>训练</strong>模型表示通过有标签样本来学习（确定）所有权重和偏差的理想值。在监督式学习中，机器学习算法通过以下方式构建模型：检查多个样本并尝试找出可最大限度地减少损失的模型；这一过程称为<strong>经验风险最小化</strong>。</p>
<p>损失是对糟糕预测的惩罚。也就是说，<strong>损失</strong>是一个数值，表示对于单个样本而言模型预测的准确程度。如果模型的预测完全准确，则损失为零，否则损失会较大。训练模型的目标是从所有样本中找到一组平均损失“较小”的权重和偏差。例如，图 3 左侧显示的是损失较大的模型，右侧显示的是损失较小的模型。关于此图，请注意以下几点：</p>
<ul>
<li>红色箭头表示损失。</li>
<li>蓝线表示预测。</li>
</ul>
<p><img src="/picture/google/LossSideBySide.png" alt="两个直角坐标曲线图，每个曲线图显示一条线和一些数据点。在第一个曲线图中，线与数据极其不吻合，所以损失较大。在第二个曲线图中，线与数据比较吻合，所以损失较小。"></p>
<p><strong>图 3. 左侧模型的损失较大；右侧模型的损失较小。</strong></p>
<p>请注意，左侧曲线图中的红色箭头比右侧曲线图中的对应红色箭头长得多。显然，相较于左侧曲线图中的蓝线，右侧曲线图中的蓝线代表的是预测效果更好的模型。</p>
<p>您可能想知道自己能否创建一个数学函数（损失函数），以有意义的方式汇总各个损失。</p>
<p><strong>平方损失：一种常见的损失函数</strong></p>
<p>接下来我们要看的线性回归模型使用的是一种称为<strong>平方损失</strong>（又称为 <strong>L2 损失</strong>）的损失函数。单个样本的平方损失如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">= 标签和预测差的平方</span><br><span class="line">= (observation - prediction(x))2</span><br><span class="line">= (y - y&apos;)2</span><br></pre></td></tr></table></figure>
<p><strong>均方误差</strong> (<strong>MSE</strong>) 指的是每个样本的平均平方损失。要计算 MSE，请求出各个样本的所有平方损失之和，然后除以样本数量：
$$
MSE = \frac{1}{N}\sum_{(x,y)\in D}(y - prediction(x))^2
$$
其中：</p>
<ul>
<li>$ (x, y)$ 指的是样本，其中<ul>
<li>$x $ 指的是模型进行预测时使用的特征集（例如，温度、年龄和交配成功率）。</li>
<li>$y$ 指的是样本的标签（例如，每分钟的鸣叫次数）。</li>
</ul>
</li>
<li>$prediction(x)$指的是权重和偏差与特征集  结合的函数。</li>
<li>$D$指的是包含多个有标签样本（即 $ (x, y)$）的数据集。</li>
<li>$N$指的是$D$中的样本数量。</li>
</ul>
<p>虽然 MSE 常用于机器学习，但它既不是唯一实用的损失函数，也不是适用于所有情形的最佳损失函数。</p>
<h2 id="3-降低误差"><a href="#3-降低误差" class="headerlink" title="3.降低误差"></a>3.降低误差</h2><h3 id="迭代方法"><a href="#迭代方法" class="headerlink" title="迭代方法"></a>迭代方法</h3><p>迭代学习可能会让您想到“<a href="http://www.howcast.com/videos/258352-how-to-play-hot-and-cold/" target="_blank" rel="noopener">Hot and Cold</a>”这种寻找隐藏物品（如顶针）的儿童游戏。在我们的游戏中，“隐藏的物品”就是最佳模型。刚开始，您会胡乱猜测（“ $ w_1$ 的值为 0。”），等待系统告诉您损失是多少。然后，您再尝试另一种猜测（“ $ w_1$ 的值为 0.5。”），看看损失是多少。哎呀，这次更接近目标了。实际上，如果您以正确方式玩这个游戏，通常会越来越接近目标。这个游戏真正棘手的地方在于尽可能高效地找到最佳模型。</p>
<p>下图显示了机器学习算法用于训练模型的迭代试错过程：</p>
<p><img src="/picture/google/GradientDescentDiagram.svg" alt="从特征和标签到模型和预测的循环。"></p>
<p><strong>图 1. 用于训练模型的迭代方法。</strong></p>
<p>我们将在整个机器学习速成课程中使用相同的迭代方法详细说明各种复杂情况，尤其是处于暴风雨中的蓝云区域。迭代策略在机器学习中的应用非常普遍，这主要是因为它们可以很好地扩展到大型数据集。</p>
<p>“模型”部分将一个或多个特征作为输入，然后返回一个预测 (y’) 作为输出。为了进行简化，不妨考虑一种采用一个特征并返回一个预测的模型：
$$
y’ = b + w_1x_1
$$
我们应该为$ b$和$ w_1$设置哪些初始值？对于线性回归问题，事实证明初始值并不重要。我们可以随机选择值，不过我们还是选择采用以下这些无关紧要的值：</p>
<ul>
<li>$ b$ = 0</li>
<li>$ w_1$ = 0</li>
</ul>
<p>假设第一个特征值是 10。将该特征值代入预测函数会得到以下结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">y&apos; = 0 + 0(10)</span><br><span class="line">y&apos; = 0</span><br></pre></td></tr></table></figure>
<p>图中的“计算损失”部分是模型将要使用的损失函数。假设我们使用平方损失函数。损失函数将采用两个输入值：</p>
<ul>
<li>y’：模型对特征 x 的预测</li>
<li>y：特征 x 对应的正确标签。</li>
</ul>
<p>最后，我们来看图的“计算参数更新”部分。机器学习系统就是在此部分检查损失函数的值，并为$ b$和  $w_1$生成新值。现在，假设这个神秘的绿色框会产生新值，然后机器学习系统将根据所有标签重新评估所有特征，为损失函数生成一个新值，而该值又产生新的参数值。这种学习过程会持续迭代，直到该算法发现损失可能最低的模型参数。通常，您可以不断迭代，直到总体损失不再变化或至少变化极其缓慢为止。这时候，我们可以说该模型已<strong>收敛</strong>。</p>
<h3 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h3><p>迭代方法图（<a href="https://developers.google.com/machine-learning/crash-course/reducing-loss/an-iterative-approach#ml-block-diagram" target="_blank" rel="noopener">图 1</a>）包含一个标题为“计算参数更新”的华而不实的绿框。现在，我们将用更实质的方法代替这种华而不实的算法。</p>
<p>假设我们有时间和计算资源来计算$w_1$的所有可能值的损失。对于我们一直在研究的回归问题，所产生的损失与$w_1$的图形始终是凸形。换言之，图形始终是碗状图，如下所示：</p>
<p><img src="/picture/google/convex.svg" alt="U 形曲线上的第二个点，这个点更接近最低点。"></p>
<p><strong>图 2. 回归问题产生的损失与权重图为凸形。</strong></p>
<p>凸形问题只有一个最低点；即只存在一个斜率<strong>正好为 0</strong> 的位置。这个最小值就是损失函数收敛之处。</p>
<p>通过计算整个数据集中  每个可能值的损失函数来找到收敛点这种方法效率太低。我们来研究一种更好的机制，这种机制在机器学习领域非常热门，称为<strong>梯度下降法</strong>。</p>
<p>梯度下降法的第一个阶段是为 $w_1$ 选择一个起始值（起点）。起点并不重要；因此很多算法就直接将 $w_1$ 设为 0 或随机选择一个值。下图显示的是我们选择了一个稍大于 0 的起点：</p>
<p><img src="/picture/google/GradientDescentStartingPoint.svg" alt="U 形曲线上的第二个点，这个点更接近最低点。"></p>
<p><strong>图 3. 梯度下降法的起点。</strong></p>
<p>然后，梯度下降法算法会计算损失曲线在起点处的梯度。简而言之，<strong>梯度</strong>是偏导数的矢量；它可以让您了解哪个方向距离目标“更近”或“更远”。请注意，损失相对于单个权重的梯度（如图 3 所示）就等于导数。</p>
<p>▸<strong>详细了解偏导数和梯度。</strong></p>
<p>请注意，梯度是一个矢量，因此具有以下两个特征：</p>
<ul>
<li>方向</li>
<li>大小</li>
</ul>
<p>梯度始终指向损失函数中增长最为迅猛的方向。梯度下降法算法会沿着负梯度的方向走一步，以便尽快降低损失。</p>
<p><img src="/picture/google/GradientDescentNegativeGradient.svg" alt="U 形曲线上的第二个点，这个点更接近最低点。"></p>
<p><strong>图 4. 梯度下降法依赖于负梯度。</strong></p>
<p>为了确定损失函数曲线上的下一个点，梯度下降法算法会将梯度大小的一部分与起点相加，如下图所示：</p>
<p><img src="/picture/google/GradientDescentGradientStep.svg" alt="U 形曲线上的第二个点，这个点更接近最低点。"></p>
<p><strong>图 5. 一个梯度步长将我们移动到损失曲线上的下一个点。</strong></p>
<p>然后，梯度下降法会重复此过程，逐渐接近最低点。</p>
<h3 id="学习速率"><a href="#学习速率" class="headerlink" title="学习速率"></a>学习速率</h3><p>正如之前所述，梯度矢量具有方向和大小。梯度下降法算法用梯度乘以一个称为<strong>学习速率</strong>（有时也称为<strong>步长</strong>）的标量，以确定下一个点的位置。例如，如果梯度大小为 2.5，学习速率为 0.01，则梯度下降法算法会选择距离前一个点 0.025 的位置作为下一个点。</p>
<p><strong>超参数</strong>是编程人员在机器学习算法中用于调整的旋钮。大多数机器学习编程人员会花费相当多的时间来调整学习速率。如果您选择的学习速率过小，就会花费太长的学习时间：</p>
<p><img src="/picture/google/LearningRateTooSmall.svg" alt="相同的 U 形曲线。很多点都相互非常接近，它们的轨迹朝着 U 形底部缓慢前进。"></p>
<p><strong>图 6. 学习速率过小。</strong></p>
<p>相反，如果您指定的学习速率过大，下一个点将永远在 U 形曲线的底部随意弹跳，就好像量子力学实验出现了严重错误一样：</p>
<p><img src="/picture/google/LearningRateTooLarge.svg" alt="相同的 U 形曲线。这条曲线包含的点非常少。点的轨迹会跳过 U 形底部，然后再次跳回。"></p>
<p><strong>图 7. 学习速率过大。</strong></p>
<p>每个回归问题都存在一个<a href="https://wikipedia.org/wiki/Goldilocks_principle" target="_blank" rel="noopener">金发姑娘</a>学习速率。“金发姑娘”值与损失函数的平坦程度相关。如果您知道损失函数的梯度较小，则可以放心地试着采用更大的学习速率，以补偿较小的梯度并获得更大的步长。</p>
<p><img src="/picture/google/LearningRateJustRight.svg" alt="相同的 U 形曲线。点的轨迹大约需要 8 步达到最低点。"></p>
<p><strong>图 8. 学习速率恰恰好。</strong></p>
<h3 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h3><p>在梯度下降法中，<strong>批量</strong>指的是用于在单次迭代中计算梯度的样本总数。到目前为止，我们一直假定批量是指整个数据集。就 Google 的规模而言，数据集通常包含数十亿甚至数千亿个样本。此外，Google 数据集通常包含海量特征。因此，一个批量可能相当巨大。如果是超大批量，则单次迭代就可能要花费很长时间进行计算。</p>
<p>包含随机抽样样本的大型数据集可能包含冗余数据。实际上，批量大小越大，出现冗余的可能性就越高。一些冗余可能有助于消除杂乱的梯度，但超大批量所具备的预测价值往往并不比大型批量高。</p>
<p>如果我们可以通过更少的计算量得出正确的平均梯度，会怎么样？通过从我们的数据集中随机选择样本，我们可以通过小得多的数据集估算（尽管过程非常杂乱）出较大的平均值。 <strong>随机梯度下降法</strong>(<strong>SGD</strong>) 将这种想法运用到极致，它每次迭代只使用一个样本（批量大小为 1）。如果进行足够的迭代，SGD 也可以发挥作用，但过程会非常杂乱。“随机”这一术语表示构成各个批量的一个样本都是随机选择的。</p>
<p><strong>小批量随机梯度下降法</strong>（<strong>小批量 SGD</strong>）是介于全批量迭代与 SGD 之间的折衷方案。小批量通常包含 <strong>10-1000</strong> 个随机选择的样本。小批量 SGD 可以减少 SGD 中的杂乱样本数量，但仍然比全批量更高效。</p>
<p>为了简化说明，我们只针对单个特征重点介绍了梯度下降法。请放心，梯度下降法也适用于包含多个特征的特征集。</p>
<h2 id="使用-TensorFlow-的起始步骤"><a href="#使用-TensorFlow-的起始步骤" class="headerlink" title="使用 TensorFlow 的起始步骤"></a>使用 TensorFlow 的起始步骤</h2><h3 id="工具包"><a href="#工具包" class="headerlink" title="工具包"></a>工具包</h3><p>下图显示了 TensorFlow 工具包的当前层次结构：</p>
<p><img src="/picture/google/TFHierarchy.svg" alt="TensorFlow 工具包的层次结构。Estimators 位于顶级。"></p>
<p><strong>图 1. TensorFlow 工具包层次结构。</strong></p>
<p>下表总结了不同层的用途：</p>
<p><div style="width:device-width;overflow:auto">
  <table border="1" class="dataframe">
    <thead>
      <tr style="text-align: right;">
        <th>工具包</th>
        <th>说明</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>Estimator (tf.estimator)  </td>
        <td>高级 OOP API。</td>
      </tr>
      <tr>
        <td>tf.layers/tf.losses/tf.metrics</td>
        <td>用于常见模型组件的库。</td>
      </tr>
      <tr>
        <td>TensorFlow</td>
        <td>低级 API </td>
      </tr>
TensorFlow 由以下两个组件组成：</tbody></table></div></p>
<ul>
<li><a href="https://www.tensorflow.org/extend/tool_developers/#protocol_buffers" target="_blank" rel="noopener">图协议缓冲区</a></li>
<li>执行（分布式）图的运行时</li>
</ul>
<p>这两个组件类似于 Java 编译器和 JVM。正如 JVM 会实施在多个硬件平台（CPU 和 GPU）上一样，TensorFlow 也是如此。</p>
<p>您应该使用哪个 API？您应该使用能够解决问题的最高级抽象层。较高级别的抽象层更易于使用，但（设计方面）不够灵活。我们建议您先从最高级 API 入手，让所有组件正常运作起来。如果您希望在某些特殊建模方面能够更加灵活一些，则可以降低一个级别。请注意，每个级别都是使用低级 API 构建的，因此降低层次结构级别应该比较直观。</p>
<h3 id="tf-estimator-API"><a href="#tf-estimator-API" class="headerlink" title="tf.estimator API"></a>tf.estimator API</h3><p>我们将使用 tf.estimator 来完成机器学习速成课程中的大部分练习。您在练习中所做的一切都可以在较低级别（原始）的 TensorFlow 中完成，但使用 tf.estimator 会大大减少代码行数。</p>
<p>tf.estimator 与 scikit-learn API 兼容。 <a href="http://scikit-learn.org/" target="_blank" rel="noopener">scikit-learn</a> 是极其热门的 Python 开放源代码机器学习库，拥有超过 10 万名用户，其中包括许多 Google 员工。</p>
<p>概括而言，以下是在 tf.estimator 中实现的线性回归程序的格式：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set up a linear classifier.</span></span><br><span class="line">classifier = tf.estimator.LinearClassifier()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Train the model on some example data.</span></span><br><span class="line">classifier.train(input_fn=train_input_fn, steps=<span class="number">2000</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use it to predict.</span></span><br><span class="line">predictions = classifier.predict(input_fn=predict_input_fn)</span><br></pre></td></tr></table></figure>

  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
          <li><a href="/">Home</a></li>
          <li><a href="/archives/">Writing</a></li>
          <li><a href="/search/">Search</a></li>
      </ul>
    </div>
    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-框架处理"><span class="toc-number">1.</span> <span class="toc-text">1.框架处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#监督式机器学习"><span class="toc-number">1.1.</span> <span class="toc-text">监督式机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#标签"><span class="toc-number">1.2.</span> <span class="toc-text">标签</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#特征"><span class="toc-number">1.3.</span> <span class="toc-text">特征</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#样本"><span class="toc-number">1.4.</span> <span class="toc-text">样本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#模型"><span class="toc-number">1.5.</span> <span class="toc-text">模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#回归与分类"><span class="toc-number">1.6.</span> <span class="toc-text">回归与分类</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-深入了解机器学习"><span class="toc-number">2.</span> <span class="toc-text">2.深入了解机器学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#线性回归"><span class="toc-number">2.1.</span> <span class="toc-text">线性回归</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练与损失"><span class="toc-number">2.2.</span> <span class="toc-text">训练与损失</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-降低误差"><span class="toc-number">3.</span> <span class="toc-text">3.降低误差</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#迭代方法"><span class="toc-number">3.1.</span> <span class="toc-text">迭代方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#梯度下降法"><span class="toc-number">3.2.</span> <span class="toc-text">梯度下降法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#学习速率"><span class="toc-number">3.3.</span> <span class="toc-text">学习速率</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#随机梯度下降法"><span class="toc-number">3.4.</span> <span class="toc-text">随机梯度下降法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#使用-TensorFlow-的起始步骤"><span class="toc-number">4.</span> <span class="toc-text">使用 TensorFlow 的起始步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#工具包"><span class="toc-number">4.1.</span> <span class="toc-text">工具包</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#tf-estimator-API"><span class="toc-number">4.2.</span> <span class="toc-text">tf.estimator API</span></a></li></ol></li></ol>
    </div>


    <div id="actions-footer" style="z-index: 9999; position: fixed ! important; right: 6px; bottom: 45px;">
      <img src="/images/menu.png" id="menu" href="#" onclick="$('#nav-footer').toggle();return false;" width="25" height="25"><br>
      <img src="/images/toc.png" id="toc" href="#" onclick="$('#toc-footer').toggle();return false;" width="25" height="25"><br>
      <img src="/images/top.png" id="top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" width="25" height="25">
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    2018
    Yummy
  </div>
  <div class="footer-right">
    <a href="/">
      <img src="/picture/footer.png" width=100% height=17 alt="pic" align="right">
    </a>
  </div>
</footer>
    </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>
<!-- styles -->
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">

<!-- jquery -->
<script src="/lib/jquery/jquery.min.js"></script>
<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/main.js"></script>
<!-- search -->

<!-- Google Analytics -->

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


